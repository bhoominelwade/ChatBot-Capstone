{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n",
      "Requirement already satisfied: torch in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (4.44.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from torch) (1.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from transformers) (0.24.5)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from transformers) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv\n",
    "!pip install -U torch transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemma Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:23<00:00, 11.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "ACCESS_TOKEN = os.getenv(\"ACCESS_TOKEN\")  # Reads .env file with ACCESS_TOKEN=<your hugging face access token>\n",
    "\n",
    "# Model ID and Tokenizer\n",
    "model_id = \"google/gemma-2b-it\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, token=ACCESS_TOKEN)\n",
    "\n",
    "# Load the model for CPU (no quantization for CPU)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, token=ACCESS_TOKEN)\n",
    "model.eval()\n",
    "\n",
    "# Set device to CPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)  # Ensure the model is on the correct device\n",
    "\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "# Example code to test model (optional)\n",
    "# input_text = \"Hello, how are you?\"\n",
    "# inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "# outputs = model.generate(**inputs)\n",
    "# print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's a detailed answer to the question:\n",
      "\n",
      "**What is a Transformer?**\n",
      "\n",
      "A transformer is an electrical device that transfers energy from one circuit to another through an alternating current (AC) current. It consists of two or more coils of wire wound around a core of ferromagnetic material, such as iron or silicon. When an alternating current is passed through the primary coil, it creates a magnetic field. This magnetic field then induces an alternating current in the secondary coil, even if the coils are separated by a gap.\n",
      "\n",
      "**How it works:**\n",
      "\n",
      "The transformer works based on the principle of electromagnetic induction. When an alternating current is induced in the secondary coil, it creates a magnetic field that opposes the original magnetic field in the primary coil. This induced magnetic field then causes current to flow in the secondary coil, even though the coils are separated by a gap.\n",
      "\n",
      "The turns ratio of a transformer determines the ratio of the number of turns in the primary coil to the number of turns in the secondary coil. The turns ratio is expressed as the ratio of the number of turns in the primary coil (Np) to the number of turns in the secondary coil (Ns).\n",
      "\n",
      "**Key features:**\n",
      "\n",
      "* **Core:** The\n"
     ]
    }
   ],
   "source": [
    "def inference(question: str, context: str):\n",
    "\n",
    "    if context == None or context == \"\":\n",
    "        prompt = f\"\"\"Give a detailed answer to the following question. Question: {question}\"\"\"\n",
    "    else:\n",
    "        prompt = f\"\"\"Using the information contained in the context, give a detailed answer to the question.\n",
    "            Context: {context}.\n",
    "            Question: {question}\"\"\"\n",
    "    chat = [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        # { \"role\": \"model\", \"content\": \"Recurrent Attention (RAG)** is a novel neural network architecture specifically designed\" }\n",
    "    ]\n",
    "    formatted_prompt = tokenizer.apply_chat_template(\n",
    "        chat,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "    inputs = tokenizer.encode(\n",
    "        formatted_prompt, add_special_tokens=False, return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids=inputs,\n",
    "            max_new_tokens=250,\n",
    "            do_sample=False,\n",
    "        )\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "    response = response[len(formatted_prompt) :]  # remove input prompt from reponse\n",
    "    response = response.replace(\"<eos>\", \"\")  # remove eos token\n",
    "    return response\n",
    "\n",
    "\n",
    "question = \"What is a transformer?\"\n",
    "print(inference(question=question, context=\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Loading and Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Using cached pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Using cached pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-4.3.1\n",
      "Collecting tiktoken\n",
      "  Using cached tiktoken-0.7.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from tiktoken) (2024.7.24)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2024.7.4)\n",
      "Using cached tiktoken-0.7.0-cp312-cp312-win_amd64.whl (799 kB)\n",
      "Installing collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf\n",
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loaders = [\n",
    "    PyPDFLoader(r'C:\\Users\\Ammar Abdulhussain\\Desktop\\Chatbot\\SRB_MPSTME_2023-24_jzLuNN33kE.pdf'),\n",
    "    PyPDFLoader(r'C:\\Users\\Ammar Abdulhussain\\Desktop\\Chatbot\\Ammar_A026_CF-1_B2.pdf'),\n",
    "]\n",
    "pages = []\n",
    "for loader in loaders:\n",
    "    pages.extend(loader.load())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (0.2.13)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from langchain) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from langchain) (3.10.3)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.30 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from langchain) (0.2.30)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from langchain) (0.1.99)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.3.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.30->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.30->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.30->langchain) (4.12.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.30->langchain) (3.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (0.2.12)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from langchain-community) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from langchain-community) (3.10.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.13 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from langchain-community) (0.2.13)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.30 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from langchain-community) (0.2.30)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from langchain-community) (0.1.99)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from langchain-community) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.3.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from langchain<0.3.0,>=0.2.13->langchain-community) (0.2.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from langchain<0.3.0,>=0.2.13->langchain-community) (2.8.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.30->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.30->langchain-community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.30->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from requests<3,>=2->langchain-community) (2024.7.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.30->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.13->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.13->langchain-community) (2.20.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "text_splitter = TokenTextSplitter(chunk_size=128, chunk_overlap=12)\n",
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "STUDENT RESOURCE BO OK \n",
      " (2023-24) \n",
      "Part -I \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "NMIMS (Deemed -to-be) \n",
      "UNIVERSITY  \n",
      "  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings and Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from sentence-transformers) (4.44.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from sentence-transformers) (0.24.5)\n",
      "Requirement already satisfied: Pillow in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (72.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.7.24)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from langchain_community.embeddings import (\n",
    "    HuggingFaceEmbeddings\n",
    ")\n",
    "encoder = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L12-v2', model_kwargs = {'device': \"cpu\"})\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L12-v2\", clean_up_tokenization_spaces=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07636687992454526\n"
     ]
    }
   ],
   "source": [
    "embeddings1 = encoder.embed_query(\"RAG\")\n",
    "embeddings2 = encoder.embed_query(docs[0].page_content)\n",
    "print(np.dot(embeddings1, embeddings2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.8.0.post1-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.0 in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\ammar abdulhussain\\desktop\\chatbot\\env\\lib\\site-packages (from faiss-cpu) (24.1)\n",
      "Downloading faiss_cpu-1.8.0.post1-cp312-cp312-win_amd64.whl (14.6 MB)\n",
      "   ---------------------------------------- 0.0/14.6 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.6/14.6 MB 9.3 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.4/14.6 MB 9.6 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 6.0/14.6 MB 10.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 8.4/14.6 MB 10.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.0/14.6 MB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 10.5/14.6 MB 9.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 10.7/14.6 MB 8.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.3/14.6 MB 7.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.1/14.6 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.6/14.6 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.4/14.6 MB 5.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.2/14.6 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.6/14.6 MB 5.6 MB/s eta 0:00:00\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.8.0.post1\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "faiss_db = FAISS.from_documents(docs, encoder, distance_strategy=DistanceStrategy.DOT_PRODUCT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  exposed personal \n",
      "information of millions of users. Digital forensics were used to analyze the \n",
      "compromised servers, identify the type of malware used in the attack, and \n",
      "understand how the attackers gained access. This information was crucial for \n",
      "improving PlayStation Network security and potentially identifying the culprits.  \n",
      "3. Network Forensics:  \n",
      "• Real World Example:  The Mirai botnet attack (2016)  involved a massive \n",
      "network of hacked devices launching a DDoS attack against major websites. \n",
      "Network forensics helped investigators track the origin of the attack traffic back \n",
      "SVKM’S NMIMS (Deemed -to-be University)  \n",
      "MUKESH PATEL SCHOOL OF TECHNOLOGY MANAGEMENT AND ENGINEERING  \n",
      "NAVI MUMBAI CAMPUS  \n",
      " \n",
      "deleted text messages exchanged between the victims and the suspect (\"Andy\") \n",
      "which, along with other evidence, led to the arrest of Philip Markoff.  \n",
      "2. Cyber Forensics (Digital Forensics):  \n",
      "• Example:  The Sony PlayStation Network breach (2011)  exposed personal \n",
      "information of millions of users. Digital\n",
      "SVKM’S NMIMS (Deemed -to-be University)  \n",
      "MUKESH PATEL SCHOOL OF TECHNOLOGY MANAGEMENT AND ENGINEERING  \n",
      "NAVI MUMBAI CAMPUS  \n",
      " \n",
      "Experiment No.  01 \n",
      " \n",
      "A.1 Aim:  \n",
      "Study  of Computer  Forensics  and different  types  of cyber -crimes  committed.  \n",
      " \n",
      "A.2 Prerequisite:  \n",
      "None  \n",
      " \n",
      "A.3 Outcome:  \n",
      "Students  understand \n",
      "nsics helped investigators track the origin of the attack traffic back \n",
      "to infected devices, leading to a better understanding of how botnets operate a nd \n",
      "how to mitigate future attacks.  \n",
      "4. Computer Forensics:  \n",
      "• Real World Example:  The TJX Companies data breach (2003 -2007)  involved a \n",
      "hacking ring stealing credit card information from millions of customers. \n",
      "Computer forensics on TJX's servers revealed vulnerabilities exploited by the \n",
      "hackers and helped identify the malware used to steal the data.  \n",
      "5. Browser Forensics:  \n",
      "• Real\n",
      "\n",
      "12.25  Disciplinary Proceedings: In the event of a breach of these regulations, your ac cess to some or all of the computing \n",
      "facilities may be withdrawn depending on the outcome of disciplinary proceedings. This may seriously affect your \n",
      "ability to complete your course of study satisfactorily.  \n",
      "12.26  If any student comes across any security incident s, please contact reportsecurityincidents@svkm.ac.in  \n",
      "12.27  These guidelines describe the reasonable and appropriate behaviour required by the Regulations for the Use of \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"Tell me about Sony PlayStation Network breach (2011)\"\n",
    "retrieved_docs = faiss_db.similarity_search(question, k=5)\n",
    "context = \"\".join(doc.page_content + \"\\n\" for doc in retrieved_docs)\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot use apply_chat_template() because tokenizer.chat_template is not set and no template argument was passed! For information about writing templates and setting the tokenizer.chat_template attribute, please see the documentation at https://huggingface.co/docs/transformers/main/en/chat_templating",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[9], line 13\u001b[0m, in \u001b[0;36minference\u001b[1;34m(question, context)\u001b[0m\n\u001b[0;32m      6\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mUsing the information contained in the context, give a detailed answer to the question.\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124m        Context: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124m        Question: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      9\u001b[0m chat \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     10\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt},\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# { \"role\": \"model\", \"content\": \"Recurrent Attention (RAG)** is a novel neural network architecture specifically designed\" }\u001b[39;00m\n\u001b[0;32m     12\u001b[0m ]\n\u001b[1;32m---> 13\u001b[0m formatted_prompt \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_chat_template\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_generation_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode(\n\u001b[0;32m     19\u001b[0m     formatted_prompt, add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     20\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[1;32m~\\Desktop\\Chatbot\\env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1786\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.apply_chat_template\u001b[1;34m(self, conversation, tools, documents, chat_template, add_generation_prompt, tokenize, padding, truncation, max_length, return_tensors, return_dict, return_assistant_tokens_mask, tokenizer_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1784\u001b[0m     tokenizer_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m-> 1786\u001b[0m chat_template \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_chat_template\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchat_template\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_assistant_tokens_mask \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m-?\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*generation\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*-?\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\u001b[39m, chat_template):\n\u001b[0;32m   1789\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning_once(\n\u001b[0;32m   1790\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_assistant_tokens_mask==True but chat template does not contain `\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;132;01m% g\u001b[39;00m\u001b[38;5;124meneration \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m}` keyword.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1791\u001b[0m     )\n",
      "File \u001b[1;32m~\\Desktop\\Chatbot\\env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2025\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.get_chat_template\u001b[1;34m(self, chat_template, tools)\u001b[0m\n\u001b[0;32m   2022\u001b[0m         chat_template \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchat_template\n\u001b[0;32m   2024\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2025\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2026\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use apply_chat_template() because tokenizer.chat_template is not set and no template \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2027\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margument was passed! For information about writing templates and setting the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2028\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer.chat_template attribute, please see the documentation at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2029\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/docs/transformers/main/en/chat_templating\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2030\u001b[0m         )\n\u001b[0;32m   2032\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m chat_template\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot use apply_chat_template() because tokenizer.chat_template is not set and no template argument was passed! For information about writing templates and setting the tokenizer.chat_template attribute, please see the documentation at https://huggingface.co/docs/transformers/main/en/chat_templating"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(inference(question=question, context=context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"For this answer I used the following documents:\")\n",
    "for doc in retrieved_docs:\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
